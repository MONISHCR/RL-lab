{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX0PUIiB_cYb"
      },
      "source": [
        "# Chaper 8 - Intrinsic Curiosity Module\n",
        "#### Deep Reinforcement Learning *in Action*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uOdTRM8_cYd"
      },
      "source": [
        "##### Listing 8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49YJ-DJP_cYd",
        "outputId": "2db3c4fb-9d02-4f10-a0dd-d5e167a63a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.26.2\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/721.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/721.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m716.8/721.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym_super_mario_bros==7.3.0\n",
            "  Downloading gym_super_mario_bros-7.3.0-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting nes-py==8.2.1\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (0.0.8)\n",
            "Collecting pyglet<=1.5.21,>=1.4.0 (from nes-py==8.2.1)\n",
            "  Downloading pyglet-1.5.21-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py==8.2.1) (4.66.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym, nes-py\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827627 sha256=d7bfc13a8dbacfa4a0a6c689af2e31e66f1c1e671b4ca93822e35df3295e9b1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.2.1-cp310-cp310-linux_x86_64.whl size=535718 sha256=f51697c1a889c4def45a308e4864c2f81fd67f4524d762ac1e193da9b0be404f\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/a7/d5/9aa14b15df740a53d41f702e4c795731b6c4da7925deb8476c\n",
            "Successfully built gym nes-py\n",
            "Installing collected packages: pyglet, gym, nes-py, gym_super_mario_bros\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.9 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2 gym_super_mario_bros-7.3.0 nes-py-8.2.1 pyglet-1.5.21\n"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.26.2 gym_super_mario_bros==7.3.0 nes-py==8.2.1 matplotlib torch scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import COMPLEX_MOVEMENT\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from random import shuffle\n",
        "\n",
        "# Initialize the environment\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v3', apply_api_compatibility=True, render_mode=\"rgb_array\")\n",
        "env = JoypadSpace(env, COMPLEX_MOVEMENT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nECnqjAmCQ2L",
        "outputId": "4168c7d0-84d3-4296-ff3a-2ecb6aee2d7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6xZZ3Yw_cYf",
        "outputId": "2664a694-afd9-4539-a286-c3e529c14ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "done = True\n",
        "for step in range(2500): #D\n",
        "    if done:\n",
        "        state = env.reset()\n",
        "    state, reward, done, trunc, info = env.step(env.action_space.sample())\n",
        "    env.render()\n",
        "#env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu4qyCzc_cYf"
      },
      "source": [
        "##### Listing 8.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b6RJt-vz_cYf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize #A\n",
        "import numpy as np\n",
        "\n",
        "def downscale_obs(obs, new_size=(42,42), to_gray=True):\n",
        "    if to_gray:\n",
        "        return resize(obs, new_size, anti_aliasing=True).max(axis=2) #B\n",
        "    else:\n",
        "        return resize(obs, new_size, anti_aliasing=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "5xc3NSiB_cYf",
        "outputId": "b676bda9-6bcc-4f11-e99c-fce808c56af0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x780ada162680>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(env.render())\n",
        "plt.imshow(downscale_obs(env.render()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIbjA5Gl_cYf"
      },
      "source": [
        "##### Listing 8.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8ZnPqQGY_cYg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "\n",
        "def prepare_state(state): #A\n",
        "    return torch.from_numpy(downscale_obs(state, to_gray=True)).float().unsqueeze(dim=0)\n",
        "\n",
        "\n",
        "def prepare_multi_state(state1, state2): #B\n",
        "    state1 = state1.clone()\n",
        "    tmp = torch.from_numpy(downscale_obs(state2, to_gray=True)).float()\n",
        "    state1[0][0] = state1[0][1]\n",
        "    state1[0][1] = state1[0][2]\n",
        "    state1[0][2] = tmp\n",
        "    return state1\n",
        "\n",
        "\n",
        "def prepare_initial_state(state,N=3): #C\n",
        "    state_ = torch.from_numpy(downscale_obs(state, to_gray=True)).float()\n",
        "    tmp = state_.repeat((N,1,1))\n",
        "    return tmp.unsqueeze(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1frrQRV_cYg"
      },
      "source": [
        "##### Listing 8.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZxbXZjxN_cYg"
      },
      "outputs": [],
      "source": [
        "def policy(qvalues, eps=None): #A\n",
        "    if eps is not None:\n",
        "        if torch.rand(1) < eps:\n",
        "            return torch.randint(low=0,high=7,size=(1,))\n",
        "        else:\n",
        "            return torch.argmax(qvalues)\n",
        "    else:\n",
        "        return torch.multinomial(F.softmax(F.normalize(qvalues)), num_samples=1) #B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0-wQTbV_cYh"
      },
      "source": [
        "##### Listing 8.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XupcuC8M_cYh"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ExperienceReplay:\n",
        "    def __init__(self, N=500, batch_size=100):\n",
        "        self.N = N #A\n",
        "        self.batch_size = batch_size #B\n",
        "        self.memory = []\n",
        "        self.counter = 0\n",
        "\n",
        "    def add_memory(self, state1, action, reward, state2):\n",
        "        self.counter +=1\n",
        "        if self.counter % 500 == 0: #C\n",
        "            self.shuffle_memory()\n",
        "\n",
        "        if len(self.memory) < self.N: #D\n",
        "            self.memory.append( (state1, action, reward, state2) )\n",
        "        else:\n",
        "            rand_index = np.random.randint(0,self.N-1)\n",
        "            self.memory[rand_index] = (state1, action, reward, state2)\n",
        "\n",
        "    def shuffle_memory(self): #E\n",
        "        shuffle(self.memory)\n",
        "\n",
        "    def get_batch(self): #F\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            batch_size = len(self.memory)\n",
        "        else:\n",
        "            batch_size = self.batch_size\n",
        "        if len(self.memory) < 1:\n",
        "            print(\"Error: No data in memory.\")\n",
        "            return None\n",
        "        #G\n",
        "        ind = np.random.choice(np.arange(len(self.memory)),batch_size,replace=False)\n",
        "        batch = [self.memory[i] for i in ind] #batch is a list of tuples\n",
        "        state1_batch = torch.stack([x[0].squeeze(dim=0) for x in batch],dim=0)\n",
        "        action_batch = torch.Tensor([x[1] for x in batch]).long()\n",
        "        reward_batch = torch.Tensor([x[2] for x in batch])\n",
        "        state2_batch = torch.stack([x[3].squeeze(dim=0) for x in batch],dim=0)\n",
        "        return state1_batch, action_batch, reward_batch, state2_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2VmCax6_cYh"
      },
      "source": [
        "##### Listing 8.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L1Ibl7QF_cYh"
      },
      "outputs": [],
      "source": [
        "class Phi(nn.Module): #A\n",
        "    def __init__(self):\n",
        "        super(Phi, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.normalize(x)\n",
        "        y = F.elu(self.conv1(x))\n",
        "        y = F.elu(self.conv2(y))\n",
        "        y = F.elu(self.conv3(y))\n",
        "        y = F.elu(self.conv4(y)) #size [1, 32, 3, 3] batch, channels, 3 x 3\n",
        "        y = y.flatten(start_dim=1) #size N, 288\n",
        "        return y\n",
        "\n",
        "class Gnet(nn.Module): #B\n",
        "    def __init__(self):\n",
        "        super(Gnet, self).__init__()\n",
        "        self.linear1 = nn.Linear(576,256)\n",
        "        self.linear2 = nn.Linear(256,12)\n",
        "\n",
        "    def forward(self, state1,state2):\n",
        "        x = torch.cat( (state1, state2) ,dim=1)\n",
        "        y = F.relu(self.linear1(x))\n",
        "        y = self.linear2(y)\n",
        "        y = F.softmax(y,dim=1)\n",
        "        return y\n",
        "\n",
        "class Fnet(nn.Module): #C\n",
        "    def __init__(self):\n",
        "        super(Fnet, self).__init__()\n",
        "        self.linear1 = nn.Linear(300,256)\n",
        "        self.linear2 = nn.Linear(256,288)\n",
        "\n",
        "    def forward(self,state,action):\n",
        "        action_ = torch.zeros(action.shape[0],12) #D\n",
        "        indices = torch.stack( (torch.arange(action.shape[0]), action.squeeze()), dim=0)\n",
        "        indices = indices.tolist()\n",
        "        action_[indices] = 1.\n",
        "        x = torch.cat( (state,action_) ,dim=1)\n",
        "        y = F.relu(self.linear1(x))\n",
        "        y = self.linear2(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR6jNXM1_cYh"
      },
      "source": [
        "##### Listing 8.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c9V7Ajxp_cYh"
      },
      "outputs": [],
      "source": [
        "class Qnetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Qnetwork, self).__init__()\n",
        "        #in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
        "        self.linear1 = nn.Linear(288,100)\n",
        "        self.linear2 = nn.Linear(100,12)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.normalize(x)\n",
        "        y = F.elu(self.conv1(x))\n",
        "        y = F.elu(self.conv2(y))\n",
        "        y = F.elu(self.conv3(y))\n",
        "        y = F.elu(self.conv4(y))\n",
        "        y = y.flatten(start_dim=2)\n",
        "        y = y.view(y.shape[0], -1, 32)\n",
        "        y = y.flatten(start_dim=1)\n",
        "        y = F.elu(self.linear1(y))\n",
        "        y = self.linear2(y) #size N, 12\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l7ods0H_cYh"
      },
      "source": [
        "##### Listing 8.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HaDmAKSs_cYh"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'batch_size':150,\n",
        "    'beta':0.2,\n",
        "    'lambda':0.1,\n",
        "    'eta': 1.0,\n",
        "    'gamma':0.2,\n",
        "    'max_episode_len':100,\n",
        "    'min_progress':15,\n",
        "    'action_repeats':6,\n",
        "    'frames_per_state':3\n",
        "}\n",
        "\n",
        "replay = ExperienceReplay(N=1000, batch_size=params['batch_size'])\n",
        "Qmodel = Qnetwork()\n",
        "encoder = Phi()\n",
        "forward_model = Fnet()\n",
        "inverse_model = Gnet()\n",
        "forward_loss = nn.MSELoss(reduction='none')\n",
        "inverse_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "qloss = nn.MSELoss()\n",
        "all_model_params = list(Qmodel.parameters()) + list(encoder.parameters()) #A\n",
        "all_model_params += list(forward_model.parameters()) + list(inverse_model.parameters())\n",
        "opt = optim.Adam(lr=0.001, params=all_model_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZtquC86_cYh"
      },
      "source": [
        "##### Listing 8.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sYst5Csv_cYi"
      },
      "outputs": [],
      "source": [
        "def loss_fn(q_loss, inverse_loss, forward_loss):\n",
        "    loss_ = (1 - params['beta']) * inverse_loss\n",
        "    loss_ += params['beta'] * forward_loss\n",
        "    loss_ = loss_.sum() / loss_.flatten().shape[0]\n",
        "    loss = loss_ + params['lambda'] * q_loss\n",
        "    return loss\n",
        "\n",
        "def reset_env():\n",
        "    \"\"\"\n",
        "    Reset the environment and return a new initial state\n",
        "    \"\"\"\n",
        "    env.reset()\n",
        "    state1 = prepare_initial_state(env.render())\n",
        "    return state1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSe3YKHE_cYi"
      },
      "source": [
        "##### Listing 8.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rKudKsAq_cYi"
      },
      "outputs": [],
      "source": [
        "def ICM(state1, action, state2, forward_scale=1., inverse_scale=1e4):\n",
        "    state1_hat = encoder(state1) #A\n",
        "    state2_hat = encoder(state2)\n",
        "    state2_hat_pred = forward_model(state1_hat.detach(), action.detach()) #B\n",
        "    forward_pred_err = forward_scale * forward_loss(state2_hat_pred, \\\n",
        "                        state2_hat.detach()).sum(dim=1).unsqueeze(dim=1)\n",
        "    pred_action = inverse_model(state1_hat, state2_hat) #C\n",
        "    inverse_pred_err = inverse_scale * inverse_loss(pred_action, \\\n",
        "                                        action.detach().flatten()).unsqueeze(dim=1)\n",
        "    return forward_pred_err, inverse_pred_err"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul63WejY_cYi"
      },
      "source": [
        "##### Listing 8.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ouVAcCn0_cYi"
      },
      "outputs": [],
      "source": [
        "def minibatch_train(use_extrinsic=True):\n",
        "    state1_batch, action_batch, reward_batch, state2_batch = replay.get_batch()\n",
        "    action_batch = action_batch.view(action_batch.shape[0],1) #A\n",
        "    reward_batch = reward_batch.view(reward_batch.shape[0],1)\n",
        "\n",
        "    forward_pred_err, inverse_pred_err = ICM(state1_batch, action_batch, state2_batch) #B\n",
        "    i_reward = (1. / params['eta']) * forward_pred_err #C\n",
        "    reward = i_reward.detach() #D\n",
        "    if use_explicit: #E\n",
        "        reward += reward_batch\n",
        "    qvals = Qmodel(state2_batch) #F\n",
        "    reward += params['gamma'] * torch.max(qvals)\n",
        "    reward_pred = Qmodel(state1_batch)\n",
        "    reward_target = reward_pred.clone()\n",
        "    indices = torch.stack( (torch.arange(action_batch.shape[0]), \\\n",
        "    action_batch.squeeze()), dim=0)\n",
        "    indices = indices.tolist()\n",
        "    reward_target[indices] = reward.squeeze()\n",
        "    q_loss = 1e5 * qloss(F.normalize(reward_pred), F.normalize(reward_target.detach()))\n",
        "    return forward_pred_err, inverse_pred_err, q_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4j4so_T_cYi"
      },
      "source": [
        "##### Listing 8.13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRgdtie__cYi",
        "outputId": "577d9988-280e-4438-ec64-5bc3aefab9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-8acb8fb27d16>:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return torch.multinomial(F.softmax(F.normalize(qvalues)), num_samples=1) #B\n"
          ]
        }
      ],
      "source": [
        "epochs = 5000\n",
        "env.reset()\n",
        "state1 = prepare_initial_state(env.render())\n",
        "eps=0.15\n",
        "losses = []\n",
        "episode_length = 0\n",
        "switch_to_eps_greedy = 1000\n",
        "state_deque = deque(maxlen=params['frames_per_state'])\n",
        "e_reward = 0.\n",
        "last_x_pos = 0 #A\n",
        "#ep_lengths = []\n",
        "use_explicit = False\n",
        "for i in range(epochs):\n",
        "    opt.zero_grad()\n",
        "    episode_length += 1\n",
        "    q_val_pred = Qmodel(state1) #B\n",
        "    if i > switch_to_eps_greedy: #C\n",
        "        action = int(policy(q_val_pred,eps))\n",
        "    else:\n",
        "        action = int(policy(q_val_pred))\n",
        "    for j in range(params['action_repeats']): #D\n",
        "        state2, e_reward_, done, trunc, info = env.step(action)\n",
        "        last_x_pos = info['x_pos']\n",
        "        if done:\n",
        "            state1 = reset_env()\n",
        "            break\n",
        "        e_reward += e_reward_\n",
        "        state_deque.append(prepare_state(state2))\n",
        "    state2 = torch.stack(list(state_deque),dim=1) #E\n",
        "    replay.add_memory(state1, action, e_reward, state2) #F\n",
        "    e_reward = 0\n",
        "    if episode_length > params['max_episode_len']: #G\n",
        "        if (info['x_pos'] - last_x_pos) < params['min_progress']:\n",
        "            done = True\n",
        "        else:\n",
        "            last_x_pos = info['x_pos']\n",
        "    if done or trunc:\n",
        "        #ep_lengths.append(info['x_pos'])\n",
        "        state1 = reset_env()\n",
        "        last_x_pos = 0\n",
        "        episode_length = 0\n",
        "    else:\n",
        "        state1 = state2\n",
        "    if len(replay.memory) < params['batch_size']:\n",
        "        continue\n",
        "    forward_pred_err, inverse_pred_err, q_loss = minibatch_train(use_extrinsic=False) #H\n",
        "    loss = loss_fn(q_loss, forward_pred_err, inverse_pred_err) #I\n",
        "    loss_list = (q_loss.mean(), forward_pred_err.flatten().mean(),\\\n",
        "    inverse_pred_err.flatten().mean())\n",
        "    losses.append(loss_list)\n",
        "    loss.backward()\n",
        "    opt.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qmkRWop6_cYi"
      },
      "outputs": [],
      "source": [
        "done = True\n",
        "state_deque = deque(maxlen=params['frames_per_state'])\n",
        "for step in range(500):\n",
        "    if done:\n",
        "        env.reset()\n",
        "        state1 = prepare_initial_state(env.render())\n",
        "    q_val_pred = Qmodel(state1)\n",
        "    action = int(policy(q_val_pred,eps))\n",
        "    state2, reward, done, trunc, info = env.step(action)\n",
        "    state2 = prepare_multi_state(state1,state2)\n",
        "    state1=state2\n",
        "    env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "R-KV36r__cYi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}